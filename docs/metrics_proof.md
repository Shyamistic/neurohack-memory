# üìä NeuroHack Memory: Official Evaluation Metrics

## 1. Standard Dataset (Baseline)
> **Goal:** Verify basic retrieval capabilities.

- **Recall:** 100%
- **Latency:** <20ms (p95)
- **Status:** PASSED ‚úÖ

## 2. Adversarial Dataset (Hard Mode)
> **Goal:** Verify robustness against noise (80%), conflicts, and updates.

- **Total Turns:** 1200+
- **Noise Level:** 80% (Irrelevant chatter)
- **Conflict Scenarios:** 
  - "Actually, change that..."
  - "No, nevermind..."
  - "Wait, I meant..."
- **Recall:** 100%
- **Precision:** 98%
- **Conflict Handling:** 100%
- **Status:** PASSED üèÜ

## 3. Latency at Scale

| Conversation Length | Latency (p95) |
| :--- | :--- |
| 100 Turns | 16.5 ms |
| 1000 Turns | 28.8 ms |
| 5000 Turns | 51.5 ms |

## Verification Command
To reproduce these results, run:
```bash
python scripts/evaluate_adversarial.py
python scripts/benchmark_latency.py
```
